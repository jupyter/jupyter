{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Atomization Workflow\n",
    "\n",
    "**Primary Layer: Daily Atomization Outputs**\n",
    "\n",
    "This notebook demonstrates the recursive text atomization methodology for literary-computational scholarship.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Process literary texts through:\n",
    "- N-gram frequency analysis\n",
    "- Entropy measurements\n",
    "- Glyph fusion mappings\n",
    "- Recursive pattern detection\n",
    "\n",
    "Outputs: Daily Markdown + consolidated JSON archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "from atomization import TextAtomizer, NGramExtractor, EntropyAnalyzer, GlyphFusionMapper\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Text Corpus\n",
    "\n",
    "Load your literary text (Odyssey, Metamorphoses, Beowulf, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load from file\n",
    "corpus_path = project_root / 'data' / 'raw' / 'corpora' / 'odyssey_excerpt.txt'\n",
    "\n",
    "# For demo, use sample text\n",
    "sample_text = \"\"\"\n",
    "Sing to me of the man, Muse, the man of twists and turns\n",
    "driven time and again off course, once he had plundered\n",
    "the hallowed heights of Troy. Many cities of men he saw and learned their minds,\n",
    "many pains he suffered, heartsick on the open sea,\n",
    "fighting to save his life and bring his comrades home.\n",
    "But he could not save them from disaster, hard as he strove—\n",
    "the recklessness of their own ways destroyed them all,\n",
    "the blind fools, they devoured the cattle of the Sun\n",
    "and the Sungod wiped from sight the day of their return.\n",
    "Launch out on his story, Muse, daughter of Zeus,\n",
    "start from where you will—sing for our time too.\n",
    "\"\"\"\n",
    "\n",
    "# Try to load from file, fall back to sample\n",
    "if corpus_path.exists():\n",
    "    with open(corpus_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "else:\n",
    "    print(f\"Corpus file not found at {corpus_path}\")\n",
    "    print(\"Using sample Odyssey excerpt...\")\n",
    "    text = sample_text\n",
    "\n",
    "print(f\"Loaded text: {len(text)} characters, {len(text.split())} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Text Atomizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomizer = TextAtomizer(\n",
    "    text=text,\n",
    "    title=\"Odyssey - Opening Invocation\",\n",
    "    metadata={\n",
    "        'author': 'Homer',\n",
    "        'translator': 'Robert Fagles',\n",
    "        'genre': 'epic poetry',\n",
    "        'tradition': 'Greek'\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Atomizer initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Execute Atomization Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = atomizer.atomize(\n",
    "    ngram_range=(1, 3),  # unigrams through trigrams\n",
    "    top_n=20,\n",
    "    calculate_entropy=True,\n",
    "    map_glyphs=True\n",
    ")\n",
    "\n",
    "print(\"Atomization complete!\")\n",
    "print(f\"Analyzed {results['metadata']['word_count']} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore N-gram Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TOP UNIGRAMS\")\n",
    "print(\"=\" * 60)\n",
    "for item in results['ngrams']['1-grams'][:10]:\n",
    "    print(f\"  {item['text']:20} → {item['frequency']:3} occurrences\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TOP BIGRAMS\")\n",
    "print(\"=\" * 60)\n",
    "for item in results['ngrams']['2-grams'][:10]:\n",
    "    print(f\"  {item['text']:30} → {item['frequency']:3} occurrences\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TOP TRIGRAMS\")\n",
    "print(\"=\" * 60)\n",
    "for item in results['ngrams']['3-grams'][:10]:\n",
    "    print(f\"  {item['text']:40} → {item['frequency']:3} occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entropy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "entropy_metrics = results['entropy']\n",
    "\n",
    "print(\"ENTROPY METRICS\")\n",
    "print(\"=\" * 60)\n",
    "for metric, value in entropy_metrics.items():\n",
    "    print(f\"  {metric.replace('_', ' ').title():30} → {value:.4f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "metrics = list(entropy_metrics.keys())\n",
    "values = list(entropy_metrics.values())\n",
    "\n",
    "ax.barh(metrics, values, color='steelblue')\n",
    "ax.set_xlabel('Value')\n",
    "ax.set_title('Text Complexity Metrics')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Glyph Fusion Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GLYPH FUSION MAPPINGS\")\n",
    "print(\"=\" * 60)\n",
    "for fusion in results['glyph_fusions'][:15]:\n",
    "    print(f\"  {fusion['pattern']:30} → {fusion['glyph']:3} ({fusion['type']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Daily Outputs\n",
    "\n",
    "Generate Markdown report + JSON archive (Primary Layer format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = project_root / 'data' / 'processed' / 'atomization'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "md_path, json_path = atomizer.export_daily_output(output_dir)\n",
    "\n",
    "print(f\"Exported outputs:\")\n",
    "print(f\"  Markdown: {md_path}\")\n",
    "print(f\"  JSON:     {json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Recursive Analysis Across Multiple Texts\n",
    "\n",
    "Compare atomization results across different works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load consolidated archive\n",
    "if json_path.exists():\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        archive = json.load(f)\n",
    "    \n",
    "    print(f\"Archive contains {len(archive)} atomization runs\")\n",
    "    \n",
    "    # Compare entropy metrics across runs\n",
    "    if len(archive) > 1:\n",
    "        dates = [item['date'] for item in archive]\n",
    "        shannon_entropies = [item['entropy']['shannon_entropy'] for item in archive]\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(dates, shannon_entropies, marker='o')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Shannon Entropy')\n",
    "        plt.title('Entropy Evolution Across Atomization Runs')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Iterate daily**: Run atomization on different text excerpts\n",
    "2. **Compare works**: Analyze Odyssey vs. Metamorphoses vs. Beowulf\n",
    "3. **Track patterns**: Monitor how entropy and n-grams evolve\n",
    "4. **Feed to AI scholarship**: Use atomization results as input for Claude/GPT analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
